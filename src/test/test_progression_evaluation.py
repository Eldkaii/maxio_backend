import pytest
from fastapi.testclient import TestClient
from sqlalchemy.orm import Session

from src.models.player import Player
from src.schemas.player_schema import PlayerStatsUpdate
from src.services.player_service import update_player_stats
from src.test.utils_common_methods import TestUtils
from src.utils.logger_config import test_logger as logger

utils = TestUtils()


@pytest.mark.nivel("bajo")
def test_stat_progression_up_high_evaluator(client: TestClient, db_session: Session):
    logger.info("üéØ Test: Evaluaci√≥n repetida para ver la progresi√≥n de stats")

    # Crear jugador evaluado con stats medias
    evaluated_name = "player_avg_progress"
    utils.create_player(client, evaluated_name)
    evaluated: Player = db_session.query(Player).filter_by(name=evaluated_name).first()
    evaluated.punteria = 50
    evaluated.velocidad = 50
    evaluated.dribbling = 50
    evaluated.defensa = 50
    evaluated.magia = 50
    evaluated.elo = 1300  # ELO aceptable

    # Crear evaluador con stats altas
    evaluator_name = "player_strong_progress"
    utils.create_player(client, evaluator_name)
    evaluator: Player = db_session.query(Player).filter_by(name=evaluator_name).first()
    evaluator.punteria = 90
    evaluator.velocidad = 90
    evaluator.dribbling = 90
    evaluator.defensa = 90
    evaluator.magia = 90
    evaluator.elo = 1150  # ELO aceptable

    db_session.commit()

    logger.info(f"‚úÖ Evaluado: {evaluated.name} (velocidad inicial: {evaluated.velocidad}, elo: {evaluated.elo})")
    logger.info(f"‚úÖ Evaluador: {evaluator.name} (velocidad: {evaluator.velocidad}, elo: {evaluator.elo})")

    # Evaluar 15 veces seguidas con aumento en velocidad
    velocidades = []
    for i in range(35):
        logger.info(f"üîÅ Evaluaci√≥n {i+1}/35")
        stats_input = PlayerStatsUpdate(velocidad=87)  # input positivo

        updated = update_player_stats(
            target_username=evaluated.name,
            evaluator_username=evaluator.name,
            stats_data=stats_input,
            db=db_session
        )

        velocidades.append(updated.velocidad)
        logger.info(f"‚û° Velocidad despu√©s de evaluaci√≥n {i+1}: {updated.velocidad}")

    # Validaciones finales
    assert all(v <= 100 for v in velocidades), "‚ùå La velocidad se pas√≥ del l√≠mite m√°ximo (100)"
    assert velocidades[0] > 50, "‚ùå La velocidad no deber√≠a mantenerse igual tras la primera evaluaci√≥n"
    assert velocidades == sorted(velocidades), "‚ùå La velocidad no est√° aumentando progresivamente"
    logger.info("‚úÖ Progresi√≥n de velocidad verificada correctamente")


@pytest.mark.nivel("bajo")
def test_stat_progression_up_mediocre_evaluator(client: TestClient, db_session: Session):
    logger.info("üéØ Test: Evaluaci√≥n repetida para ver la progresi√≥n de stats")

    # Crear jugador evaluado con stats medias
    evaluated_name = "player_avg_progress"
    utils.create_player(client, evaluated_name)
    evaluated: Player = db_session.query(Player).filter_by(name=evaluated_name).first()
    evaluated.punteria = 50
    evaluated.velocidad = 50
    evaluated.dribbling = 50
    evaluated.defensa = 50
    evaluated.magia = 50
    evaluated.elo = 1300  # ELO aceptable

    # Crear evaluador con stats altas
    evaluator_name = "player_strong_progress"
    utils.create_player(client, evaluator_name)
    evaluator: Player = db_session.query(Player).filter_by(name=evaluator_name).first()
    evaluator.punteria = 55
    evaluator.velocidad = 55
    evaluator.dribbling = 55
    evaluator.defensa = 55
    evaluator.magia = 55
    evaluator.elo = 1150  # ELO aceptable

    db_session.commit()

    logger.info(f"‚úÖ Evaluado: {evaluated.name} (velocidad inicial: {evaluated.velocidad}, elo: {evaluated.elo})")
    logger.info(f"‚úÖ Evaluador: {evaluator.name} (velocidad: {evaluator.velocidad}, elo: {evaluator.elo})")

    # Evaluar 15 veces seguidas con aumento en velocidad
    velocidades = []
    for i in range(35):
        logger.info(f"üîÅ Evaluaci√≥n {i+1}/35")
        stats_input = PlayerStatsUpdate(velocidad=87)  # input positivo

        updated = update_player_stats(
            target_username=evaluated.name,
            evaluator_username=evaluator.name,
            stats_data=stats_input,
            db=db_session
        )

        velocidades.append(updated.velocidad)
        logger.info(f"‚û° Velocidad despu√©s de evaluaci√≥n {i+1}: {updated.velocidad}")

    # Validaciones finales
    assert all(v <= 100 for v in velocidades), "‚ùå La velocidad se pas√≥ del l√≠mite m√°ximo (100)"
    assert velocidades[0] > 50, "‚ùå La velocidad no deber√≠a mantenerse igual tras la primera evaluaci√≥n"
    assert velocidades == sorted(velocidades), "‚ùå La velocidad no est√° aumentando progresivamente"
    logger.info("‚úÖ Progresi√≥n de velocidad verificada correctamente")



@pytest.mark.nivel("bajo")
def test_stat_degression_down_bad_evaluator(client: TestClient, db_session: Session):
    logger.info("üß™ Test: Evaluaci√≥n negativa desde evaluador d√©bil hacia jugador promedio")

    # Crear jugador evaluado con stats medias
    evaluated_name = "player_avg_regression"
    utils.create_player(client, evaluated_name)
    evaluated: Player = db_session.query(Player).filter_by(name=evaluated_name).first()
    evaluated.punteria = 50
    evaluated.velocidad = 50
    evaluated.dribbling = 50
    evaluated.defensa = 50
    evaluated.magia = 50
    evaluated.elo = 50  # ELO aceptable

    # Crear evaluador con stats bajas
    evaluator_name = "player_weak_evaluator"
    utils.create_player(client, evaluator_name)
    evaluator: Player = db_session.query(Player).filter_by(name=evaluator_name).first()
    evaluator.punteria = 30
    evaluator.velocidad = 30
    evaluator.dribbling = 30
    evaluator.defensa = 30
    evaluator.magia = 30
    evaluator.elo = 800  # ELO aceptable

    db_session.commit()

    logger.info(f"üü¢ Evaluado: {evaluated.name} (velocidad inicial: {evaluated.velocidad}, elo: {evaluated.elo})")
    logger.info(f"üî¥ Evaluador: {evaluator.name} (velocidad: {evaluator.velocidad}, elo: {evaluator.elo})")

    velocidades = []

    for i in range(30):
        logger.info(f"‚è¨ Evaluaci√≥n negativa {i+1}/30")
        stats_input = PlayerStatsUpdate(velocidad=20)

        updated = update_player_stats(
            target_username=evaluated.name,
            evaluator_username=evaluator.name,
            stats_data=stats_input,
            db=db_session
        )

        velocidades.append(updated.velocidad)
        logger.info(f"üìâ Velocidad despu√©s de evaluaci√≥n {i+1}: {updated.velocidad}")

    # Validaciones
    assert all(v >= 0 for v in velocidades), "‚ùå La velocidad baj√≥ por debajo de 0"
    assert velocidades[0] < 50, "‚ùå No se redujo la velocidad tras la primera evaluaci√≥n"
    assert velocidades == sorted(velocidades, reverse=True), "‚ùå La velocidad no est√° bajando progresivamente"

    logger.info("‚úÖ Regresi√≥n de velocidad verificada correctamente")

@pytest.mark.nivel("bajo")
def test_stat_degression_down_mediocre_evaluator(client: TestClient, db_session: Session):
    logger.info("üß™ Test: Evaluaci√≥n negativa desde evaluador d√©bil hacia jugador promedio")

    # Crear jugador evaluado con stats medias
    evaluated_name = "player_avg_regression"
    utils.create_player(client, evaluated_name)
    evaluated: Player = db_session.query(Player).filter_by(name=evaluated_name).first()
    evaluated.punteria = 50
    evaluated.velocidad = 50
    evaluated.dribbling = 50
    evaluated.defensa = 50
    evaluated.magia = 50
    evaluated.elo = 800  # ELO aceptable

    # Crear evaluador con stats bajas
    evaluator_name = "player_weak_evaluator"
    utils.create_player(client, evaluator_name)
    evaluator: Player = db_session.query(Player).filter_by(name=evaluator_name).first()
    evaluator.punteria = 55
    evaluator.velocidad = 55
    evaluator.dribbling = 55
    evaluator.defensa = 55
    evaluator.magia = 55
    evaluator.elo = 800  # ELO aceptale

    db_session.commit()

    logger.info(f"üü¢ Evaluado: {evaluated.name} (velocidad inicial: {evaluated.velocidad}, elo: {evaluated.elo})")
    logger.info(f"üî¥ Evaluador: {evaluator.name} (velocidad: {evaluator.velocidad}, elo: {evaluator.elo})")

    velocidades = []

    for i in range(30):
        logger.info(f"‚è¨ Evaluaci√≥n negativa {i+1}/30")
        stats_input = PlayerStatsUpdate(velocidad=20)

        updated = update_player_stats(
            target_username=evaluated.name,
            evaluator_username=evaluator.name,
            stats_data=stats_input,
            db=db_session
        )

        velocidades.append(updated.velocidad)
        logger.info(f"üìâ Velocidad despu√©s de evaluaci√≥n {i+1}: {updated.velocidad}")

    # Validaciones
    assert all(v >= 0 for v in velocidades), "‚ùå La velocidad baj√≥ por debajo de 0"
    assert velocidades[0] < 50, "‚ùå No se redujo la velocidad tras la primera evaluaci√≥n"
    assert velocidades == sorted(velocidades, reverse=True), "‚ùå La velocidad no est√° bajando progresivamente"

    logger.info("‚úÖ Regresi√≥n de velocidad verificada correctamente")